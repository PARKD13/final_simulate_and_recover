# final_simulate_and_recover
The simulate-and-recover task focuses on how reliable parameter estimation can be over multiple samples, especially across different sample sizes in our programs. We observe that as the sample size increases, parameter recovery improves, while the squared error for drift rate decreases. This highlights the significance of using sufficiently large sample sizes to obtain reliable parameter estimates. Across all sample sizes, drift rate and non-decision time consistently exhibit negative bias, indicating underestimation, while boundary separation shows a positive bias, or overestimation. This pattern suggests a potential systematic issue with parameter recovery rather than random error, pointing to possible limitations in the methodology used. The drift rate demonstrated the greatest positive change with larger sample sizes. Boundary separation and non decision time also showed improvements but they were not as significant as the drift rate.

According to our summary, drift rate consistently has the greatest absolute bias which we can see because values are sharply more extreme when sample size is low and vice versa, whereas non-decision time displayed the least bias, by demonstrating little change even with increased sample size. The increasing sample size also revealed disparities in squared errors. At N=10, the drift rate squared error was much larger than that for boundary separation and significantly greater than for non-decision time. This suggests that drift rate estimation is highly sensitive to sampling noise, especially with smaller samples. However, for the largest sample size, these disparities decreased significantly, indicating that larger sample sizes can improve even the most sensitive parameters.
While improvements in parameter recovery continue with larger sample sizes, the rate of improvement diminishes, which points to a theoretical limit to recovery precision even with very large samples. The most significant decrease in squared error for drift rate occurred between sample sizes 10 and 40, with smaller improvements between sample sizes 40 and 4000. This highlights a trade-off for researchers: smaller sample sizes may suffice for estimating boundary and non-decision time, but larger samples are crucial for reliable drift rate estimates. Small samples yield unreliable estimates, particularly for drift rate, making them unsuitable for serious analysis. Moderate sample sizes show some improvement but still exhibit considerable bias and variance. Large samples provide more reliable estimates, though systematic biases persist. The continued presence of systematic biases, even with large samples, raises concerns about the method and practices used to generate synthetic data.

In conclusion, the simulation and recovery exercise emphasizes the statistical properties of parameter recovery methods when applying computational models to empirical data. Our results emphasize the need for caution especially when interpreting results from small samples and suggest that systematic corrections are necessary to address known biases in parameter estimation. However, we also realized that samples can never be ideal or perfect even in great numbers, which reveals the limitations of sampling. Using confidence intervals instead of point estimates, is a solution to be more careful in interpreting results. Researchers must be critical in how they come to their conclusions, and be humble in their results, as samples will never provide perfect inference to the population. Nevertheless statistical inference with synthetic data is still an effective and important tool to know more about populations in the world with ease, and it has numerous implications for the hopeful benefit of our society. 

DISCLAIMER: AI helped create my code