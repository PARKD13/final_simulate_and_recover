# final_simulate_and_recover
The simulate-and-recover task focuses on how reliable parameter estimation can be over multiple samples, especially across different sample sizes in our programs. In out program, we observed that as the sample size increases, parameter recovery improves, while the squared error for drift rate decreases. It is imperative that we use sufficiently large sample sizes in order to obtain reliable parameter estimates. Across all sample sizes, drift rate and non-decision time consistently exhibit negative bias, indicating underestimation, while boundary separation shows a positive bias, or overestimation.

According to our summary, drift rate has the greatest bias which we can see because values are more extreme when sample size is low and the values get closer to zero as sample size increases. Non-decision time displayed the least bias, by demonstrating little change even with increased sample size. The increasing sample size also revealed the differences in squared errors. At a sample size of 10, the squared error of the drift rate was much larger than the squared error of boundary separation and significantly greater than squared error for non-decision time. In the summary we can see that drift rate is most sensitive to noise, especially with smaller samples. However, when sample sizes increase, these differences decreased, showing a negative correlation. The most significant decrease in squared error for drift rate occurred between sample sizes 10 and 40, with smaller improvements between sample sizes 40 and 4000. Smaller sample sizes are ideal for estimating boundary and non-decision time, but larger samples are ideal for reliable drift rate estimates. Small samples yield unreliable estimates, especially for drift rate, making them unsuitable for serious analysis. Moderate sample sizes show some improvement but still exhibit considerable bias and variance. Large samples provide more reliable estimates, though systematic biases persist. The continued presence of systematic biases, even with large samples, raises concerns about the method and practices used to generate synthetic data. It's also important to note that While improvements in parameter recovery continue with larger sample sizes, the rate of improvement does not. This reveals that we cannot perfectly estimate parameters and that perfect predictions only work in theory and not in real world practice. 

In conclusion, the simulation and recovery exercise emphasizes the statistical properties and processes of parameter recovery methods when applying computational models to observed data. Our results show the potential lack of reliability and precision computational simulation can have especially when interpreting results from small samples. Ultimately, this means that systematic corrections are necessary to address bias in parameter estimation. However, we also realized that samples can never be ideal or perfect even in great numbers, which reveals the limitations of sampling. Using confidence intervals instead of point estimates, is a solution to be more careful in interpreting results. Researchers must be critical in how they come to their conclusions, and be humble in their results, as samples will never provide perfect inference to the population. Nevertheless statistical inference with synthetic data is still an effective and important tool to know more about populations in the world with ease, and it has numerous implications for the hopeful benefit of our society. 

DISCLAIMER: AI helped create my code